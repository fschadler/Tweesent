from tweepy import API
from tweepy.streaming import StreamListener
from tweepy import OAuthHandler
from tweepy import Stream

from textblob import TextBlob, Word, WordList

import twitter_credentials

import numpy as np
import pandas as pd
import re

# User Input: Defines the search term and amount of Tweets that shall be analyzed.

######  Add predefined # infront of user Input, but if User manually adds # remove it "If str contains # remove "#""
hash_tag_list = input("Enter keyword/hashtag: ")
num_terms = input("Enter how many Tweets should be included: ")


class TwitterClient():
    def __init__(self):
        self.auth = TwitterAuthenticator().authenticate_twitter_app()
        self.twitter_client = API(self.auth)

    def get_twitter_client_api(self):
        return self.twitter_client

# TWITTER AUTHENTICATOR
"""
Uses twitter_credentials.py to get access to API 
"""


class TwitterAuthenticator():

    def authenticate_twitter_app(self):
        auth = OAuthHandler(twitter_credentials.CONSUMER_KEY, twitter_credentials.CONSUMER_SECRET)
        auth.set_access_token(twitter_credentials.ACCESS_TOKEN, twitter_credentials.ACCESS_TOKEN_SECRET)
        return auth


#TWITTER STREAMER
class TwitterStreamer():
    """
    Class for streaming and processing live tweets.
    """

    def __init__(self):
        self.twitter_autenthicator = TwitterAuthenticator()

    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):
        # This handles Twitter authentification and the connection to Twitter Streaming API
        listener = TwitterListener(fetched_tweets_filename)
        auth = self.twitter_authenticator.authenticate_twitter_app()
        stream = Stream(auth, listener)

        # Filter based on User Input
        stream.filter(track=hash_tag_list)


# TWITTER STREAM LISTENER
class TwitterListener(StreamListener):
    """
    This is a basic listener that just prints received tweets to stdout.
    """

    def __init__(self, fetched_tweets_filename):
        self.fetched_tweets_filename = fetched_tweets_filename

    def on_data(self, data):
        try:
            print(data)
            with open(self.fetched_tweets_filename, 'a') as tf:
                tf.write(data)
            return True
        except BaseException as e:
            print("Error on_data %s" % str(e))
        return True

    def on_error(self, status):
        if status == 420:
            # Returning False on_data method in case rate limit occurs.
            return False
        print(status)


class TweetAnalyzer():
    """
    Functionality for analyzing and categorizing content from tweets.
    """

    def clean_tweet(self, tweet):
        return ' '.join(re.sub("(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)", " ", tweet).split())

#    def translate_tweet(self,tweet):
#        language = TextBlob(self.clean_tweet(tweet))
#        detected_language = language.detect_language()
#        for language in self.clean_tweet(tweet):
#            if language.detect_language != "en":
#                return language.translate(from_lang=detected_language, to=u"en")

    def analyze_sentiment(self, tweet):
        analysis = TextBlob(self.clean_tweet(tweet))

        return analysis.sentiment.polarity

    def tweets_to_data_frame(self, tweets):
        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['tweets'])

        df['id'] = np.array([tweet.id for tweet in tweets]) #Tweet Object
        df['len'] = np.array([len(tweet.text) for tweet in tweets]) #Tweet Object
        df['date'] = np.array([tweet.created_at for tweet in tweets]) #Tweet Object
        df['user_id'] = np.array([tweet.user.id for tweet in tweets]) #User Object
        df['user_screen_name'] = np.array([tweet.user.screen_name for tweet in tweets]) #User Object
        df['follower_count'] = np.array([tweet.user.followers_count for tweet in tweets]) #User Object
        df['location'] = np.array([tweet.coordinates for tweet in tweets]) #Tweet Object
       
       return df


if __name__ == '__main__':
    twitter_client = TwitterClient()
    tweet_analyzer = TweetAnalyzer()

    api = twitter_client.get_twitter_client_api()
    # Tweets filtered based on manual user input
    tweets = api.search(q = hash_tag_list , count = num_terms)
    df = tweet_analyzer.tweets_to_data_frame(tweets)
   
   # Adds Sentiment Score to dataframe 
    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])
    # Additional dataframe which only displays Tweets of users with 10.000 or more followers
    df_follower = df.loc[df['follower_count'] > 10000]
    
    # Prints all Tweets and Sentiment Score
    print(df.head(int(num_terms)))
    # Prints the average score of the loaded Tweets
    print("Average Sentiment Score of ", hash_tag_list, ", including ", num_terms, "Tweets is: ", sum(df["sentiment"])/len(df["sentiment"]))
    # Prints only Tweets with more then 10000 followers
    print(df_follower)
